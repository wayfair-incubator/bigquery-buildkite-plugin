#!/bin/bash
set -euo pipefail

# retry <number-of-retries> <command>
function retry {
	local retries=$1
	shift
	local attempts=1
	local status=0

	until "$@"; do
		status=$?
		echo "Exited with $status"
		if ((retries == "0")); then
			return $status
		elif ((attempts == retries)); then
			echo "Failed $attempts retries"
			return $status
		else
			echo "Retrying $((retries - attempts)) more times..."
			attempts=$((attempts + 1))
			sleep $(((attempts - 2) * 2))
		fi
	done
}

PLUGIN_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/.."

# Create secure temporary file for credentials
PIPELINE_FILE=$(mktemp)
chmod 600 "$PIPELINE_FILE"

# Ensure cleanup on exit, error, interrupt, or termination
trap 'rm -f "$PIPELINE_FILE"' EXIT ERR INT TERM

debug_mode="false"
if [[ ${BUILDKITE_PLUGIN_BIGQUERY_DEBUG_MODE:-false} =~ (true|on|1) ]]; then
	echo "--- :hammer: Enabling debug mode"
	debug_mode="true"
fi

workdir="/workdir"

default_image="python:3.14-slim"
image="${BUILDKITE_PLUGIN_BIGQUERY_CUSTOM_IMAGE:-$default_image}"

if [ -z "$BUILDKITE_PLUGIN_BIGQUERY_GCP_PROJECT" ]; then
	echo "ERROR: bigquery project (gcp_project) key not set"
	exit 1
fi

gcp_project="${BUILDKITE_PLUGIN_BIGQUERY_GCP_PROJECT}"

if [ -z "${BUILDKITE_PLUGIN_BIGQUERY_DATASET_SCHEMA_DIRECTORY}" ]; then
	echo "ERROR: dataset schema (dataset_schema_directory) not set"
	exit 1
fi

dataset_schema_directory="${BUILDKITE_PLUGIN_BIGQUERY_DATASET_SCHEMA_DIRECTORY}"

if [ -z "${gcp_service_account}" ]; then
	echo "ERROR: gcp service account (gcp_service_account) not set"
	exit 1
fi

execute_only_changed_files=0
if [[ ${BUILDKITE_PLUGIN_BIGQUERY_EXECUTE_ONLY_CHANGED_FILES:-false} =~ (true|on|1) ]]; then
	execute_only_changed_files=1
fi

default_prod_build_branch="master"
prod_build_branch="${BUILDKITE_PLUGIN_BIGQUERY_PROD_BUILD_BRANCH:-$default_prod_build_branch}"

default_current_branch="non_master"
current_branch="${BUILDKITE_BRANCH:-$default_current_branch}"

# Get changed files with proper error handling and absolute paths
changed_files=""
is_default_branch="false"

if [[ ${prod_build_branch} == "${current_branch}" ]]; then
	is_default_branch="true"
	echo "--- :git: Detecting changed files on default branch (${current_branch})"

	# For default branch, compare with parent commit
	if git rev-parse HEAD^ >/dev/null 2>&1; then
		raw_files=$(git diff-tree --diff-filter=ABMRT --no-commit-id --name-only -r HEAD^..HEAD 2>/dev/null || echo "")
	else
		# First commit, use all files
		echo "âš ï¸  First commit detected, will process all files"
		raw_files=""
	fi
else
	echo "--- :git: Detecting changed files on feature branch (${current_branch})"

	# For feature branches, compare with origin base branch
	base_branch="origin/${prod_build_branch}"
	if git rev-parse --verify "$base_branch" >/dev/null 2>&1; then
		# Use three-dot syntax for merge-base comparison
		raw_files=$(git diff --diff-filter=ABMRT --name-only "${base_branch}...HEAD" 2>/dev/null || echo "")
	else
		echo "âš ï¸  Warning: Could not find base branch $base_branch"
		echo "âš ï¸  Falling back to comparing with HEAD^"
		raw_files=$(git diff-tree --diff-filter=ABMRT --no-commit-id --name-only -r HEAD^..HEAD 2>/dev/null || echo "")
	fi
fi

# Convert relative paths to absolute paths and format as comma-separated list
if [[ -n $raw_files ]]; then
	abs_changed_files=""
	while IFS= read -r file; do
		if [[ -n $file ]]; then
			# Convert to absolute path
			if [[ -e $file ]]; then
				abs_path="$(cd "$(dirname "$file")" && pwd)/$(basename "$file")"
				abs_changed_files="${abs_changed_files}${abs_path},"
			fi
		fi
	done <<<"$raw_files"

	# Remove trailing comma
	changed_files="${abs_changed_files%,}"

	if [[ -n $changed_files ]]; then
		file_count=$(echo "$changed_files" | tr ',' '\n' | wc -l)
		echo "ðŸ“ Detected ${file_count} changed file(s)"
	fi
else
	echo "âš ï¸  No changed files detected, will process all files in directory"
fi

default_fail_pipeline_on_first_exception="true"
fail_pipeline_on_first_exception="${BUILDKITE_PLUGIN_BIGQUERY_DEFAULT_FAIL_PIPELINE_ON_FIRST_EXCEPTION:-$default_fail_pipeline_on_first_exception}"

echo "$gcp_service_account" >"$PIPELINE_FILE"

if [[ ${debug_mode} == "true" ]]; then
	echo "Configuration:"
	echo "GCP Project: ${gcp_project}"
	echo "Dataset Schema Directory: ${dataset_schema_directory}"
	echo "Execute Only Changed Files: ${execute_only_changed_files}"
	echo "Fail Pipeline on First Exception: ${fail_pipeline_on_first_exception}"
	echo "Changed Files: ${changed_files}"
	echo "Is Default Branch: ${is_default_branch}"
	echo "Docker Image: ${image}"
fi

args=("-it" "--rm" "--init" "--workdir" "${workdir}")

# Propagate all environment variables into the container
if [[ -n ${BUILDKITE_ENV_FILE:=""} ]]; then
	# Read in the env file and convert to --env params for docker
	# This is because --env-file doesn't support newlines or quotes per https://docs.docker.com/compose/env-file/#syntax-rules
	while read -r var; do
		args+=(--env "${var%%=*}")
	done <"$BUILDKITE_ENV_FILE"
else
	echo 'ðŸš¨ Not propagating environment variables to container as $BUILDKITE_ENV_FILE is not set'
fi

# Mount the buildkite-agent
if [[ -z ${BUILDKITE_AGENT_BINARY_PATH:=""} ]]; then
	if ! command -v buildkite-agent >/dev/null 2>&1; then
		echo "+++ ðŸš¨ Failed to find buildkite-agent in PATH to mount into container"
		exit 1
	else
		BUILDKITE_AGENT_BINARY_PATH=$(command -v buildkite-agent)
	fi
fi
args+=(
	"--env" "BUILDKITE_JOB_ID"
	"--env" "BUILDKITE_BUILD_ID"
	"--env" "BUILDKITE_AGENT_ACCESS_TOKEN"
	"--env" "dataset_schema_directory=$dataset_schema_directory"
	"--env" "gcp_project=$gcp_project"
	"--env" "execute_only_changed_files=$execute_only_changed_files"
	"--env" "fail_pipeline_on_first_exception=$fail_pipeline_on_first_exception"
	"--env" "credentials=$(<"$PIPELINE_FILE")"
	"--volume" "$BUILDKITE_AGENT_BINARY_PATH:/usr/bin/buildkite-agent"
)

# Add the image in before the shell and command
args+=("${image}")

# Assemble the shell and command arguments into the docker arguments
command=()
display_command=()

shell=("/bin/sh" "-e" "-c")
args+=("${shell[@]}")
display_command+=("${shell[@]}")
command+=("pip install --quiet uv && export updated_files=${changed_files} && uv pip install --system -q -r plugin_scripts/requirements.lock && python -m plugin_scripts.__init__")

# join command lines
command_string="$(
	IFS=$'\n'
	echo "${command[*]}"
)"

args+=("${command_string}")
display_command+=("'${command_string}'")

echo "--- :docker: Pulling ${image}"
if ! retry "${BUILDKITE_PLUGIN_CLOUD_FUNCTIONS_DOCKER_PULL_RETRIES:-3}" \
	docker pull "${image}"; then
	rv=$?
	echo "--- :docker: Pull failed."
	exit $rv
fi

echo '--- :docker: Logging "docker create" command'
echo "$ docker create" >&2

echo "--- :docker: Running command in ${image}"
echo "$ ${display_command[*]}" >&2

if [[ ${debug_mode} == "true" ]]; then
	echo "docker create" >&2
	echo "docker cp \"${PWD}/.\" \"dockerContainerID:${workdir}\"" >&2
fi

# # For copy-checkout, we have to `docker create`, then `docker cp "${PWD}:${workdir}"`, then `docker start`
DOCKERID=$(docker create "${args[@]}") # substitute any backticks
docker cp "${PWD}/." "${DOCKERID}:${workdir}"
docker cp "${PLUGIN_DIR}/plugin_scripts" "${DOCKERID}:${workdir}/plugin_scripts"
docker start -a "${DOCKERID}"
